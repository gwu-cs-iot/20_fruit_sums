# Report

## High Level Overview
- Fruit Sums is a simple project which logs the number of newly purchased groceries using a raspberry pi. To start, the system first collects images of fruits and vegetables waved in front of the picamera using motion detection. Then, it extracts labels from each captured image using Google's Vision API to produce a list of identified fruits and vegetables. This list is then sent to a pre-set phone number, completing the detection process.  
- This system also utilizes a push button and an LED. The purpose of the push button is to allow users provide input to begin the detection process, while the LED indicates when photos have been captured when motion is detected. Although users must begin the detection with the push button input, the system will automatically time out and move on to the next instruction once 10 seconds have passed without any motion detected. 
- The program separates the capture and detection process, so once the image capture process is complete, the program will then iterate through all captured images (located within a specified directory), resize them using OpenCV, and send them to the Google Vision API to receive a response which will contain all possible annotations for the given image.
- The correct annotation, if present, can be identified by comparing the returned list with the pre-defined list of fruit and vegetable types saved under the `types-of-food.txt` file. The list within this file may grow or shrink depending on the types of produce the user wishes to identify. All labels and their occurance count are then formatted into a message string and sent to the user's configured phone number.

## Changes to the Original Project & What Was Not Accomplished
- Although there weren't too many changes from the original plan (as there weren't many details to the original plan), two things that have changed from what I had originally envisioned include 1) using motion detection to capture images and 2) employing the use of a push button and LED. 
	- Including motion detection to capture still images of fruits and vegetables was a last minute decision made to avoid using Tensor Flow. 
	- Adding the push button and LED was also a last minute improvisation made to include some form of feedback to the users "scanning" their items.
- Two things I wish I could have done better include 1) improving the detection algorithm and 2) improving project organization. 
- Attempting to identify fruits and vegetables without creating pre-trained models myself and avoiding the use of Tensor Flow proved to be extremely difficult. Detection was no where near accurate or meaningful enough using the initial color detection schemes with OpenCV. However, I was able to accomplish most of what I had set out for by employing Google's Vision API, which provides pre-trained machine learning models for general data sets. The system is able to easily detect apples, oranges, and tomatoes, but had some trouble identifying onions over oranges and other fruits/veggies of similar shape and color. In the future, I wish to learn how to train models myself to have a more fine grained control over the types of food detected.
- Because the motion detection and LED feedback were last minute features, it was a little bit difficult enforcing an organized structure while maintaining all functionalities. Project organization could have been improved by carefully isolating the modules into separate files and/or structuring the code differently for readability. 